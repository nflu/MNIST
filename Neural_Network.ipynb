{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip \n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f,encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "print(train_set[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#these are just various mathematical tools needed for the NN\n",
    "\n",
    "def sigmoidPrime(x):\n",
    "    return expit(x)*(1-expit(x)) #use expit to prevent overflow with large values\n",
    "\n",
    "def sigmoid(x):\n",
    "    return expit(x) #admittedly this is a little unnecessary but I think it makes sense to have \n",
    "    #sigmoid and sigmoidPrime instead of expit and sigmoidPrime\n",
    "\n",
    "def relu(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def reluPrime(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def elementWise(f, x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = f(x[i])\n",
    "    return x    \n",
    "\n",
    "def softMax(x):\n",
    "    z = np.exp(x)\n",
    "    return z/sum(z)\n",
    "\n",
    "def softMaxPrime(x):\n",
    "    z = np.exp(x)\n",
    "    c = sum(z)\n",
    "    for i in range(len(z)):\n",
    "        z[i] = (c-z[i])*z[i]/(c**2)\n",
    "    return z\n",
    "\n",
    "def display(x, label, act):\n",
    "    strn = \"\"\n",
    "    for i in range(len(x)):\n",
    "        if i%28==0:\n",
    "            print(strn)\n",
    "            strn = \"\"\n",
    "        if x[i]==0:\n",
    "            strn += \" \"\n",
    "        if x[i]>=act:\n",
    "            strn += \"x\"\n",
    "    print(label)\n",
    "            \n",
    "def logLoss(x, target):\n",
    "    loss = 0\n",
    "    for i in range(len(x)):\n",
    "        loss += target[i]*np.log(x[i])+(1-target[i])*np.log(1-x[i])\n",
    "    return (-1.0/len(x))*loss\n",
    "    \n",
    "def logLossPrime(x, target):\n",
    "    grad = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        grad[i]=(-1.0/len(x))*(target[i]/x[i]-(1-target[i])/(1-x[i]))\n",
    "    return grad\n",
    "\n",
    "def MSE(x, target):\n",
    "    a = x-target\n",
    "    return np.dot(a,a)\n",
    "\n",
    "def MSEPrime(x, target):\n",
    "    return 2*(x-target)\n",
    "\n",
    "def crossEntropy(output, target):\n",
    "    cost = 0\n",
    "    for i in range(len(target)):\n",
    "        cost -= target[i]*np.log(output[i])\n",
    "    return cost\n",
    "\n",
    "def trainingGraph(trainingData):\n",
    "    costs = trainingData[0]\n",
    "    accuracies = trainingData[1]\n",
    "    plt.plot(costs, 'ro')\n",
    "    plt.ylabel(\"total cost\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.show()\n",
    "    plt.plot(100.0*(1.0-accuracies), 'bo')\n",
    "    plt.plot(\"total error percentage\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "class Neural_Network:\n",
    "    defaultSize = 16 #default number of neurons in hidden layers if no shape list given\n",
    "    inputChecks = True #this will change whether inputs that match the MNIST format are given\n",
    "    #can be turned off to allow for debugging on smaller examples\n",
    "    \n",
    "    #activation must be an activation function that works for a single scalar \n",
    "    #and activation prime is its derivative. costFunction is a cost function for a vector representing an output layer\n",
    "    #and the target vector. costDeriv is its derivative with respect to the vector of activations.\n",
    "    #shape is list of integers where shape[i] = the number of neurons in ith layer\n",
    "    #layers is an integer describing the number of layers\n",
    "    #shape and layers are optional. if both are given the shape list will be followed, if neither are given\n",
    "    #it will use the default value for layers and make all hidden layers have defaultSize many neurons\n",
    "    def __init__(self, activation, activationPrime, costFunction, costDeriv, shape = None, layers = 4):\n",
    "        if layers<2:\n",
    "            raise NameError(\"Too few layers. Need an input layer and an output layer.\")\n",
    "        if Neural_Network.inputChecks and (shape[0] != 28**2 or shape[len(shape)-1] != 10):\n",
    "            raise NameError(\"Improper input or output layer size. \\\n",
    "                            Must be 28^2 input neurons and 10 output neurons to work with MNIST.\")\n",
    "        if shape==None:\n",
    "            shape = [28**2] + [defaultSize for i in range(layers-2)] + [10]\n",
    "        self.activation = activation\n",
    "        self.activationPrime = activationPrime\n",
    "        self.shape = shape\n",
    "        self.costFunction = costFunction\n",
    "        self.costDeriv = costDeriv\n",
    "        self.weights = Neural_Network.constructWeights(shape) \n",
    "        #weights[i] is the weights going into layer i\n",
    "        self.bias = Neural_Network.constructBias(shape)\n",
    "        #bias[i] is the bias on layer i \n",
    "        self.activations = []\n",
    "        self.zs = []\n",
    "        \n",
    "    #returns a list of matrices of weights. weights[i] is the set of weights going into ith layer\n",
    "    #weights[i][j][k] represents the weight going from the kth neuron in layer i-1 to jth neuron in layer i \n",
    "    def constructWeights(shape):\n",
    "        weights = [None]\n",
    "        for i in range(len(shape)-1): \n",
    "            weights.append(np.random.uniform(-1,1,shape[i]*shape[i+1]).reshape((shape[i+1],shape[i])))\n",
    "        return weights\n",
    "    \n",
    "    #returns a list of vectors of biases. bias[i] is the set of biases on the ith layer\n",
    "    #bias[i][j] is the bias in the ith layer on the jth neuron\n",
    "    def constructBias(shape):\n",
    "        bias = [None]\n",
    "        for i in range(1,len(shape)): \n",
    "            bias.append(np.random.uniform(-1,1,shape[i]))\n",
    "        return bias\n",
    "    \n",
    "    #performs forward propagation on the input x with the current weights and biases\n",
    "    #using activation function from the constructor returns the activations on the last layer \n",
    "    #updates the zs and activations attributes\n",
    "    def forwardProp(self, x):\n",
    "        if Neural_Network.inputChecks and len(x) != 28**2:\n",
    "            raise NameError(\"improper input\")\n",
    "        prevAct = x\n",
    "        act = []\n",
    "        self.activations = []\n",
    "        self.zs = []\n",
    "        self.activations.append(prevAct)\n",
    "        for i in range(1,len(self.shape)): #each layer\n",
    "            z = np.dot(self.weights[i], prevAct) + self.bias[i]\n",
    "            act = elementWise(self.activation, z)\n",
    "            self.activations.append(act)\n",
    "            self.zs.append(z)\n",
    "            prevAct = act\n",
    "        return act\n",
    "    \n",
    "    #returns the total cost for the neural network on all datapoints in data\n",
    "    #using cost function costFunc for each point. returns cost as a scalar\n",
    "    def totalCost(self, data, costFunc):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "        if Neural_Network.inputChecks and len(images) != len(labels):\n",
    "            raise NameError(\"improper input\")\n",
    "        target = np.zeros(10)\n",
    "        cost = 0 \n",
    "        for i in range(len(images)):\n",
    "            target[labels[i]] = 1\n",
    "            out = self.forwardProp(images[i])\n",
    "            cost += costFunc(out, target)\n",
    "            target[labels[i]] = 0\n",
    "        return cost\n",
    "        \n",
    "    #returns the classification as a scalar based on the outputActivations\n",
    "    #picks the index with highest activation\n",
    "    def classification(outputActivations):\n",
    "        maximum = -1\n",
    "        index = -1\n",
    "        for i in range(len(outputActivations)):\n",
    "            if outputActivations[i] >= maximum:\n",
    "                index = i\n",
    "                maximum = outputActivations[i]\n",
    "        return index\n",
    "     \n",
    "    #randomly initializes all weights and biases    \n",
    "    def randomInitialization(self):\n",
    "        self.weights = Neural_Network.constructWeights(self.shape) \n",
    "        self.bias = Neural_Network.constructBias(self.shape)\n",
    "    \n",
    "    #using backProp this will perform gradient descent from the current initialization of the weights\n",
    "    #and biases on the given data. data in form touple of array of images and array of labels\n",
    "    #will stop after iterations many iterations. returns a touple of the best weights and biases\n",
    "    #and a list of the costs over time. will update the weights and biases in the neural network\n",
    "    def gradientDescent(self, data, iterations, learningRate):\n",
    "        return self.stochasticGradientDescent(data, len(data[0]), iterations, learningRate)\n",
    "    \n",
    "    #will apply the gradient with stepSize where the gradient is in form \n",
    "    #given by the backProp function\n",
    "    def applyGradient(self, gradient, stepSize):\n",
    "        for i in range(1, len(gradient[0])): #for each matrix in the weight update, \n",
    "            #first value is None for convenience in indexing\n",
    "            self.weights[i] -= stepSize * gradient[0][i]\n",
    "        for i in range(1, len(gradient[1])): #for each vector in the bias update\n",
    "            self.bias[i] -= stepSize * gradient[1][i]\n",
    "    \n",
    "    #computes the correct and incorrect number of classified data points on data\n",
    "    #prints the number correct, number incorrect, percent correct, and percent incorrect\n",
    "    #returns a touple of the number correct and total number of data points\n",
    "    def validation(self, data):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "        if len(images) != len(labels):\n",
    "            raise NameError(\"improper input\")\n",
    "        correct = 0 \n",
    "        wrong = 0\n",
    "        for i in range(len(images)):\n",
    "            if (Neural_Network.classification(self.forwardProp(images[i]))) == labels[i]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "        print(\"correct: \", correct)\n",
    "        print(\"wrong: \", wrong)\n",
    "        print(\"accuracy:\", 100.0*correct/len(images), \"%\")\n",
    "        print(\"error:\", 100.0*wrong/len(images), \"%\")\n",
    "        return (correct, len(images))\n",
    "    \n",
    "    #chooses a random batch of size batchSize from images and labels\n",
    "    #note it does not replace when sampling\n",
    "    def randomBatch(images, labels, batchSize):\n",
    "        indices = np.random.choice(len(images), batchSize, replace = False)\n",
    "        #if you set replace to True this will break the gradientDescent function\n",
    "        imageBatch = []\n",
    "        labelBatch = []\n",
    "        for i in range(len(indices)):\n",
    "            imageBatch.append(images[indices[i]])\n",
    "            labelBatch.append(labels[indices[i]])\n",
    "        return (imageBatch, labelBatch)\n",
    "        \n",
    "    #using backProp this will perform stoachastic gradient descent from the current initialization of the weights\n",
    "    #and biases on the given data. will choose batchSize many samples from data \n",
    "    #data in form touple of array of images and array of labels\n",
    "    #will stop after iterations many iterations. returns a touple of the best weights and biases\n",
    "    #and a list of the costs over time. will update the weights and biases in the neural network\n",
    "    def stochasticGradientDescent(self, data, batchSize, iterations, learningRate):\n",
    "        start = time.time()\n",
    "        bestCost = sys.maxsize\n",
    "        bestWandB = []\n",
    "        costs = []\n",
    "        accuracies = []\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "        for _ in range(iterations):\n",
    "            for i in range(5): #performs 5 gradient steps before re-computing the cost for all examples\n",
    "                #this is somewhat of a hyper-parameter that just allows things to run pretty fast\n",
    "                imageSet, labelSet = Neural_Network.randomBatch(images, labels, batchSize)\n",
    "                target = np.zeros(10)\n",
    "                gradients = []\n",
    "                for i in range(len(imageSet)):\n",
    "                    target[labelSet[i]] = 1\n",
    "                    output = self.forwardProp(imageSet[i])\n",
    "                    gradients.append(self.backProp(target))\n",
    "                    target[labelSet[i]] = 0\n",
    "                self.applyGradient(self.averageGradient(gradients), learningRate)\n",
    "            cost = self.totalCost(data, self.costFunction)\n",
    "            costs.append(cost)\n",
    "            a = self.validation(data)\n",
    "            accuracies.append(a[0]/a[1])\n",
    "            print(cost)\n",
    "            if cost <= bestCost:\n",
    "                bestCost = cost\n",
    "                bestWandB = (self.weights, self.bias)\n",
    "        trainingData = (costs, accuracies)\n",
    "        end = time.time()\n",
    "        print(iterations, \"iterations took\", end - start, \"seconds.\")\n",
    "        return (bestWandB, trainingData)\n",
    "    \n",
    "    #given a list of touples of the gradient in the form given by backProp\n",
    "    #will return the average gradient\n",
    "    def averageGradient(self, gradients):\n",
    "        averageGrad = (Neural_Network.constructWeights(self.shape), Neural_Network.constructBias(self.shape))\n",
    "        for i in range(len(averageGrad)): #weights then biases\n",
    "            for j in range(len(gradients)): #grad from each sample\n",
    "                for k in range(1, len(gradients[j][i])): #grad for each matrix\n",
    "                    averageGrad[i][k] += gradients[j][i][k]\n",
    "            for k in range(1,len(averageGrad[i])):#done at end to prevent rounding small numbers to zero\n",
    "                averageGrad[i][k] /= len(gradients) #if overflow is a problem then divide at each step\n",
    "        return averageGrad\n",
    "    \n",
    "    #this will return the gradient of the cost on the single target\n",
    "    #the form is a touple with the weights and then the biases\n",
    "    #in the same format as the weights and biases attributes for the Neural_Network class\n",
    "    def backProp(self, target):\n",
    "        if Neural_Network.inputChecks and len(target) != 10:\n",
    "            raise NameError(\"improper input\")\n",
    "        biasGrad = [None for _ in range(len(self.shape))]\n",
    "        weightGrad = [None for _ in range(len(self.shape))]\n",
    "        delta = self.costDeriv(self.activations[-1], target) * self.activationPrime(self.zs[-1])\n",
    "        biasGrad[-1] = delta\n",
    "        weightGrad[-1] = np.tile(np.array([delta]).transpose(), (1,self.shape[-2]))*np.tile(np.array(self.activations[-2]),(self.shape[-1],1))\n",
    "        #this line (and the version of it below can be a little confusing, see readme)\n",
    "        for l in range(2, len(self.shape)):\n",
    "            z = self.zs[-l]\n",
    "            actDeriv = self.activationPrime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * actDeriv\n",
    "            biasGrad[-l] = delta\n",
    "            weightGrad[-l] = np.tile(np.array([delta]).transpose(), (1,self.shape[-l-1]))*np.tile(np.array(self.activations[-l-1]),(self.shape[-l],1))\n",
    "        return (weightGrad, biasGrad)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line right before the for loop in ```backProp()``` is a little confusing so I'll explain. $\\frac{\\partial C}{\\partial W^{l}_{j,k}} = a^{l-1}_{k} \\Delta^{l}_{j}$ where $C$ is the cost and $W^{l}_{j,k}$ is the weight going from the $k$th neuron in the $l-1$th layer to the $j$th neuron in the $l$th layer, $a^{l-1}_{k}$ is the activation on the $k$th neuron in the $l-1$th layer, and  $\\Delta^{l}_{j}$ is the derivative of the cost with respect to the $j$th component of $z^{l}$. If you've never seen this before, it can be confusing so draw out a simple NN with very few neurons and write out the gradient of the weight matrix. You will notice that if you make a matrix with the same dimensions as $W^{l}$ where the columns are the vector $\\Delta^{l}$ and the same dimension matrix where the rows are the row vector $(a^{l-1})^{T}$ and do element-wise multiplication (not matrix multiplication) of these matrices, then the resulting matrix is the gradient of the cost with respect to the weight matrix $W^{l}$.\n",
    "\n",
    "```np.tile``` allows you to create matrices from repeating column or row vectors. The [NumPy documentation](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.tile.html) explains it much better than I can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  9262\n",
      "wrong:  40738\n",
      "accuracy: 18.524 %\n",
      "error: 81.476 %\n",
      "44475.15697625679\n",
      "correct:  18825\n",
      "wrong:  31175\n",
      "accuracy: 37.65 %\n",
      "error: 62.35 %\n",
      "41238.37558301897\n",
      "correct:  24122\n",
      "wrong:  25878\n",
      "accuracy: 48.244 %\n",
      "error: 51.756 %\n",
      "38701.66029193807\n",
      "correct:  25864\n",
      "wrong:  24136\n",
      "accuracy: 51.728 %\n",
      "error: 48.272 %\n",
      "34212.125201942654\n",
      "correct:  29467\n",
      "wrong:  20533\n",
      "accuracy: 58.934 %\n",
      "error: 41.066 %\n",
      "32054.67673561983\n",
      "correct:  30983\n",
      "wrong:  19017\n",
      "accuracy: 61.966 %\n",
      "error: 38.034 %\n",
      "29469.841605768004\n",
      "correct:  32419\n",
      "wrong:  17581\n",
      "accuracy: 64.838 %\n",
      "error: 35.162 %\n",
      "27335.038618741393\n",
      "correct:  33592\n",
      "wrong:  16408\n",
      "accuracy: 67.184 %\n",
      "error: 32.816 %\n",
      "25800.451639535237\n",
      "correct:  34243\n",
      "wrong:  15757\n",
      "accuracy: 68.486 %\n",
      "error: 31.514 %\n",
      "24488.729849688327\n",
      "correct:  35321\n",
      "wrong:  14679\n",
      "accuracy: 70.642 %\n",
      "error: 29.358 %\n",
      "23181.935232663433\n",
      "correct:  35637\n",
      "wrong:  14363\n",
      "accuracy: 71.274 %\n",
      "error: 28.726 %\n",
      "22456.573784509044\n",
      "correct:  36917\n",
      "wrong:  13083\n",
      "accuracy: 73.834 %\n",
      "error: 26.166 %\n",
      "21476.78390410655\n",
      "correct:  37251\n",
      "wrong:  12749\n",
      "accuracy: 74.502 %\n",
      "error: 25.498 %\n",
      "20480.616621447545\n",
      "correct:  37832\n",
      "wrong:  12168\n",
      "accuracy: 75.664 %\n",
      "error: 24.336 %\n",
      "19923.72496388493\n",
      "correct:  37214\n",
      "wrong:  12786\n",
      "accuracy: 74.428 %\n",
      "error: 25.572 %\n",
      "19635.150069037973\n",
      "correct:  38096\n",
      "wrong:  11904\n",
      "accuracy: 76.192 %\n",
      "error: 23.808 %\n",
      "18799.935510314397\n",
      "correct:  38665\n",
      "wrong:  11335\n",
      "accuracy: 77.33 %\n",
      "error: 22.67 %\n",
      "18432.800980601343\n",
      "correct:  39076\n",
      "wrong:  10924\n",
      "accuracy: 78.152 %\n",
      "error: 21.848 %\n",
      "17872.371767391396\n",
      "correct:  39375\n",
      "wrong:  10625\n",
      "accuracy: 78.75 %\n",
      "error: 21.25 %\n",
      "17710.51056708646\n",
      "correct:  39429\n",
      "wrong:  10571\n",
      "accuracy: 78.858 %\n",
      "error: 21.142 %\n",
      "17299.093157475923\n",
      "correct:  39911\n",
      "wrong:  10089\n",
      "accuracy: 79.822 %\n",
      "error: 20.178 %\n",
      "16790.52216646974\n",
      "correct:  40158\n",
      "wrong:  9842\n",
      "accuracy: 80.316 %\n",
      "error: 19.684 %\n",
      "16455.549080596546\n",
      "correct:  40175\n",
      "wrong:  9825\n",
      "accuracy: 80.35 %\n",
      "error: 19.65 %\n",
      "16248.238752431462\n",
      "correct:  40449\n",
      "wrong:  9551\n",
      "accuracy: 80.898 %\n",
      "error: 19.102 %\n",
      "15944.146749543848\n",
      "correct:  40474\n",
      "wrong:  9526\n",
      "accuracy: 80.948 %\n",
      "error: 19.052 %\n",
      "15689.34655599835\n",
      "correct:  40605\n",
      "wrong:  9395\n",
      "accuracy: 81.21 %\n",
      "error: 18.79 %\n",
      "15513.91175495421\n",
      "correct:  40428\n",
      "wrong:  9572\n",
      "accuracy: 80.856 %\n",
      "error: 19.144 %\n",
      "15379.502518596022\n",
      "correct:  40440\n",
      "wrong:  9560\n",
      "accuracy: 80.88 %\n",
      "error: 19.12 %\n",
      "15246.022591712997\n",
      "correct:  40396\n",
      "wrong:  9604\n",
      "accuracy: 80.792 %\n",
      "error: 19.208 %\n",
      "15203.354866989906\n",
      "correct:  40574\n",
      "wrong:  9426\n",
      "accuracy: 81.148 %\n",
      "error: 18.852 %\n",
      "15021.206959022888\n",
      "correct:  40730\n",
      "wrong:  9270\n",
      "accuracy: 81.46 %\n",
      "error: 18.54 %\n",
      "14990.327419896463\n",
      "correct:  40860\n",
      "wrong:  9140\n",
      "accuracy: 81.72 %\n",
      "error: 18.28 %\n",
      "14653.863350278514\n",
      "correct:  40645\n",
      "wrong:  9355\n",
      "accuracy: 81.29 %\n",
      "error: 18.71 %\n",
      "14660.40766670643\n",
      "correct:  40839\n",
      "wrong:  9161\n",
      "accuracy: 81.678 %\n",
      "error: 18.322 %\n",
      "14561.66062572216\n",
      "correct:  40987\n",
      "wrong:  9013\n",
      "accuracy: 81.974 %\n",
      "error: 18.026 %\n",
      "14552.578194487292\n",
      "35 iterations took 1270.3186628818512 seconds.\n",
      "\n",
      "correct:  8315\n",
      "wrong:  1685\n",
      "accuracy: 83.15 %\n",
      "error: 16.85 %\n",
      "correct:  8301\n",
      "wrong:  1699\n",
      "accuracy: 83.01 %\n",
      "error: 16.99 %\n",
      "correct:  40980\n",
      "wrong:  9020\n",
      "accuracy: 81.96 %\n",
      "error: 18.04 %\n",
      "14431.051535253708\n",
      "correct:  40971\n",
      "wrong:  9029\n",
      "accuracy: 81.942 %\n",
      "error: 18.058 %\n",
      "14397.871983848527\n",
      "correct:  40972\n",
      "wrong:  9028\n",
      "accuracy: 81.944 %\n",
      "error: 18.056 %\n",
      "14384.348060667093\n",
      "correct:  40979\n",
      "wrong:  9021\n",
      "accuracy: 81.958 %\n",
      "error: 18.042 %\n",
      "14375.223865173553\n",
      "correct:  40990\n",
      "wrong:  9010\n",
      "accuracy: 81.98 %\n",
      "error: 18.02 %\n",
      "14366.947356091803\n",
      "correct:  41004\n",
      "wrong:  8996\n",
      "accuracy: 82.008 %\n",
      "error: 17.992 %\n",
      "14358.767852089322\n",
      "correct:  40998\n",
      "wrong:  9002\n",
      "accuracy: 81.996 %\n",
      "error: 18.004 %\n",
      "14350.559178196623\n",
      "correct:  40993\n",
      "wrong:  9007\n",
      "accuracy: 81.986 %\n",
      "error: 18.014 %\n",
      "14342.392920494942\n",
      "correct:  40996\n",
      "wrong:  9004\n",
      "accuracy: 81.992 %\n",
      "error: 18.008 %\n",
      "14334.266306546971\n",
      "correct:  40996\n",
      "wrong:  9004\n",
      "accuracy: 81.992 %\n",
      "error: 18.008 %\n",
      "14326.196697537804\n",
      "correct:  40996\n",
      "wrong:  9004\n",
      "accuracy: 81.992 %\n",
      "error: 18.008 %\n",
      "14318.249239133065\n",
      "correct:  41005\n",
      "wrong:  8995\n",
      "accuracy: 82.01 %\n",
      "error: 17.99 %\n",
      "14310.378509733338\n",
      "correct:  41014\n",
      "wrong:  8986\n",
      "accuracy: 82.028 %\n",
      "error: 17.972 %\n",
      "14302.592824505231\n",
      "correct:  41023\n",
      "wrong:  8977\n",
      "accuracy: 82.046 %\n",
      "error: 17.954 %\n",
      "14294.869971222974\n",
      "correct:  41025\n",
      "wrong:  8975\n",
      "accuracy: 82.05 %\n",
      "error: 17.95 %\n",
      "14287.239518481038\n",
      "correct:  41016\n",
      "wrong:  8984\n",
      "accuracy: 82.032 %\n",
      "error: 17.968 %\n",
      "14279.631281676513\n",
      "correct:  41018\n",
      "wrong:  8982\n",
      "accuracy: 82.036 %\n",
      "error: 17.964 %\n",
      "14272.121331269036\n",
      "correct:  41019\n",
      "wrong:  8981\n",
      "accuracy: 82.038 %\n",
      "error: 17.962 %\n",
      "14264.616231392432\n",
      "correct:  41030\n",
      "wrong:  8970\n",
      "accuracy: 82.06 %\n",
      "error: 17.94 %\n",
      "14257.129541266992\n",
      "correct:  41029\n",
      "wrong:  8971\n",
      "accuracy: 82.058 %\n",
      "error: 17.942 %\n",
      "14249.658848189058\n",
      "correct:  41027\n",
      "wrong:  8973\n",
      "accuracy: 82.054 %\n",
      "error: 17.946 %\n",
      "14242.193447864864\n",
      "correct:  41029\n",
      "wrong:  8971\n",
      "accuracy: 82.058 %\n",
      "error: 17.942 %\n",
      "14234.72849830053\n",
      "correct:  41039\n",
      "wrong:  8961\n",
      "accuracy: 82.078 %\n",
      "error: 17.922 %\n",
      "14227.3017192263\n",
      "correct:  41037\n",
      "wrong:  8963\n",
      "accuracy: 82.074 %\n",
      "error: 17.926 %\n",
      "14219.94724241692\n",
      "correct:  41040\n",
      "wrong:  8960\n",
      "accuracy: 82.08 %\n",
      "error: 17.92 %\n",
      "14212.597017888129\n",
      "correct:  41038\n",
      "wrong:  8962\n",
      "accuracy: 82.076 %\n",
      "error: 17.924 %\n",
      "14205.317990673127\n",
      "correct:  41033\n",
      "wrong:  8967\n",
      "accuracy: 82.066 %\n",
      "error: 17.934 %\n",
      "14198.069880495523\n",
      "correct:  41051\n",
      "wrong:  8949\n",
      "accuracy: 82.102 %\n",
      "error: 17.898 %\n",
      "14190.860295477332\n",
      "correct:  41062\n",
      "wrong:  8938\n",
      "accuracy: 82.124 %\n",
      "error: 17.876 %\n",
      "14183.698853692971\n",
      "correct:  41083\n",
      "wrong:  8917\n",
      "accuracy: 82.166 %\n",
      "error: 17.834 %\n",
      "14176.602364145441\n",
      "correct:  41219\n",
      "wrong:  8781\n",
      "accuracy: 82.438 %\n",
      "error: 17.562 %\n",
      "14169.620821664685\n",
      "correct:  41222\n",
      "wrong:  8778\n",
      "accuracy: 82.444 %\n",
      "error: 17.556 %\n",
      "14162.689452950071\n",
      "correct:  41257\n",
      "wrong:  8743\n",
      "accuracy: 82.514 %\n",
      "error: 17.486 %\n",
      "14155.81898794018\n",
      "correct:  41279\n",
      "wrong:  8721\n",
      "accuracy: 82.558 %\n",
      "error: 17.442 %\n",
      "14148.989096378167\n",
      "correct:  41282\n",
      "wrong:  8718\n",
      "accuracy: 82.564 %\n",
      "error: 17.436 %\n",
      "14142.198708538841\n",
      "correct:  41286\n",
      "wrong:  8714\n",
      "accuracy: 82.572 %\n",
      "error: 17.428 %\n",
      "14135.448622562279\n",
      "correct:  41297\n",
      "wrong:  8703\n",
      "accuracy: 82.594 %\n",
      "error: 17.406 %\n",
      "14128.66625022768\n",
      "correct:  41297\n",
      "wrong:  8703\n",
      "accuracy: 82.594 %\n",
      "error: 17.406 %\n",
      "14121.89216115276\n",
      "correct:  41305\n",
      "wrong:  8695\n",
      "accuracy: 82.61 %\n",
      "error: 17.39 %\n",
      "14115.142564399164\n",
      "correct:  41307\n",
      "wrong:  8693\n",
      "accuracy: 82.614 %\n",
      "error: 17.386 %\n",
      "14108.417787037777\n",
      "correct:  41309\n",
      "wrong:  8691\n",
      "accuracy: 82.618 %\n",
      "error: 17.382 %\n",
      "14101.76026117613\n",
      "correct:  41299\n",
      "wrong:  8701\n",
      "accuracy: 82.598 %\n",
      "error: 17.402 %\n",
      "14095.201806581255\n",
      "correct:  41311\n",
      "wrong:  8689\n",
      "accuracy: 82.622 %\n",
      "error: 17.378 %\n",
      "14088.725846706051\n",
      "correct:  41320\n",
      "wrong:  8680\n",
      "accuracy: 82.64 %\n",
      "error: 17.36 %\n",
      "14082.361276647987\n",
      "correct:  41303\n",
      "wrong:  8697\n",
      "accuracy: 82.606 %\n",
      "error: 17.394 %\n",
      "14076.11568193621\n",
      "correct:  41302\n",
      "wrong:  8698\n",
      "accuracy: 82.604 %\n",
      "error: 17.396 %\n",
      "14069.988900914888\n",
      "correct:  41294\n",
      "wrong:  8706\n",
      "accuracy: 82.588 %\n",
      "error: 17.412 %\n",
      "14063.946050699567\n",
      "correct:  41305\n",
      "wrong:  8695\n",
      "accuracy: 82.61 %\n",
      "error: 17.39 %\n",
      "14057.953750788502\n",
      "correct:  41304\n",
      "wrong:  8696\n",
      "accuracy: 82.608 %\n",
      "error: 17.392 %\n",
      "14052.023947934771\n",
      "correct:  41306\n",
      "wrong:  8694\n",
      "accuracy: 82.612 %\n",
      "error: 17.388 %\n",
      "14046.130223213788\n",
      "correct:  41313\n",
      "wrong:  8687\n",
      "accuracy: 82.626 %\n",
      "error: 17.374 %\n",
      "14040.328806291242\n",
      "correct:  41310\n",
      "wrong:  8690\n",
      "accuracy: 82.62 %\n",
      "error: 17.38 %\n",
      "14034.535277208644\n",
      "correct:  41308\n",
      "wrong:  8692\n",
      "accuracy: 82.616 %\n",
      "error: 17.384 %\n",
      "14028.794126181241\n",
      "correct:  41317\n",
      "wrong:  8683\n",
      "accuracy: 82.634 %\n",
      "error: 17.366 %\n",
      "14023.07985974644\n",
      "correct:  41317\n",
      "wrong:  8683\n",
      "accuracy: 82.634 %\n",
      "error: 17.366 %\n",
      "14017.392871287484\n",
      "correct:  41325\n",
      "wrong:  8675\n",
      "accuracy: 82.65 %\n",
      "error: 17.35 %\n",
      "14011.744716008297\n",
      "correct:  41332\n",
      "wrong:  8668\n",
      "accuracy: 82.664 %\n",
      "error: 17.336 %\n",
      "14006.094928520986\n",
      "correct:  41344\n",
      "wrong:  8656\n",
      "accuracy: 82.688 %\n",
      "error: 17.312 %\n",
      "14000.45795384948\n",
      "correct:  41346\n",
      "wrong:  8654\n",
      "accuracy: 82.692 %\n",
      "error: 17.308 %\n",
      "13994.913550788544\n",
      "correct:  41347\n",
      "wrong:  8653\n",
      "accuracy: 82.694 %\n",
      "error: 17.306 %\n",
      "13989.45236494337\n",
      "correct:  41352\n",
      "wrong:  8648\n",
      "accuracy: 82.704 %\n",
      "error: 17.296 %\n",
      "13984.09077790461\n",
      "correct:  41346\n",
      "wrong:  8654\n",
      "accuracy: 82.692 %\n",
      "error: 17.308 %\n",
      "13978.85394276779\n",
      "correct:  41353\n",
      "wrong:  8647\n",
      "accuracy: 82.706 %\n",
      "error: 17.294 %\n",
      "13973.691724324632\n",
      "correct:  41350\n",
      "wrong:  8650\n",
      "accuracy: 82.7 %\n",
      "error: 17.3 %\n",
      "13968.593046737597\n",
      "correct:  41347\n",
      "wrong:  8653\n",
      "accuracy: 82.694 %\n",
      "error: 17.306 %\n",
      "13963.596882848675\n",
      "correct:  41379\n",
      "wrong:  8621\n",
      "accuracy: 82.758 %\n",
      "error: 17.242 %\n",
      "13958.679378484649\n",
      "correct:  41383\n",
      "wrong:  8617\n",
      "accuracy: 82.766 %\n",
      "error: 17.234 %\n",
      "13953.809053085817\n",
      "correct:  41390\n",
      "wrong:  8610\n",
      "accuracy: 82.78 %\n",
      "error: 17.22 %\n",
      "13949.016211132173\n",
      "correct:  41392\n",
      "wrong:  8608\n",
      "accuracy: 82.784 %\n",
      "error: 17.216 %\n",
      "13944.291496041722\n",
      "correct:  41387\n",
      "wrong:  8613\n",
      "accuracy: 82.774 %\n",
      "error: 17.226 %\n",
      "13939.562664508569\n",
      "correct:  41378\n",
      "wrong:  8622\n",
      "accuracy: 82.756 %\n",
      "error: 17.244 %\n",
      "13934.83249064375\n",
      "correct:  41387\n",
      "wrong:  8613\n",
      "accuracy: 82.774 %\n",
      "error: 17.226 %\n",
      "13930.088932225024\n",
      "correct:  41392\n",
      "wrong:  8608\n",
      "accuracy: 82.784 %\n",
      "error: 17.216 %\n",
      "13925.343457584744\n",
      "correct:  41402\n",
      "wrong:  8598\n",
      "accuracy: 82.804 %\n",
      "error: 17.196 %\n",
      "13920.605241112218\n",
      "correct:  41409\n",
      "wrong:  8591\n",
      "accuracy: 82.818 %\n",
      "error: 17.182 %\n",
      "13915.958909720393\n",
      "correct:  41409\n",
      "wrong:  8591\n",
      "accuracy: 82.818 %\n",
      "error: 17.182 %\n",
      "13911.425505381354\n",
      "correct:  41415\n",
      "wrong:  8585\n",
      "accuracy: 82.83 %\n",
      "error: 17.17 %\n",
      "13906.994628429557\n",
      "correct:  41412\n",
      "wrong:  8588\n",
      "accuracy: 82.824 %\n",
      "error: 17.176 %\n",
      "13902.673340663396\n",
      "correct:  41421\n",
      "wrong:  8579\n",
      "accuracy: 82.842 %\n",
      "error: 17.158 %\n",
      "13898.481181359672\n",
      "correct:  41414\n",
      "wrong:  8586\n",
      "accuracy: 82.828 %\n",
      "error: 17.172 %\n",
      "13894.417475505948\n",
      "correct:  41411\n",
      "wrong:  8589\n",
      "accuracy: 82.822 %\n",
      "error: 17.178 %\n",
      "13890.488704598676\n",
      "correct:  41411\n",
      "wrong:  8589\n",
      "accuracy: 82.822 %\n",
      "error: 17.178 %\n",
      "13886.664071209601\n",
      "correct:  41410\n",
      "wrong:  8590\n",
      "accuracy: 82.82 %\n",
      "error: 17.18 %\n",
      "13882.984952737397\n",
      "correct:  41410\n",
      "wrong:  8590\n",
      "accuracy: 82.82 %\n",
      "error: 17.18 %\n",
      "13879.386850656329\n",
      "correct:  41415\n",
      "wrong:  8585\n",
      "accuracy: 82.83 %\n",
      "error: 17.17 %\n",
      "13875.839073589164\n",
      "correct:  41419\n",
      "wrong:  8581\n",
      "accuracy: 82.838 %\n",
      "error: 17.162 %\n",
      "13872.302136300024\n",
      "correct:  41404\n",
      "wrong:  8596\n",
      "accuracy: 82.808 %\n",
      "error: 17.192 %\n",
      "13868.76501043247\n",
      "correct:  41403\n",
      "wrong:  8597\n",
      "accuracy: 82.806 %\n",
      "error: 17.194 %\n",
      "13865.198527627635\n",
      "correct:  41399\n",
      "wrong:  8601\n",
      "accuracy: 82.798 %\n",
      "error: 17.202 %\n",
      "13861.670465452424\n",
      "correct:  41407\n",
      "wrong:  8593\n",
      "accuracy: 82.814 %\n",
      "error: 17.186 %\n",
      "13858.128514233735\n",
      "correct:  41421\n",
      "wrong:  8579\n",
      "accuracy: 82.842 %\n",
      "error: 17.158 %\n",
      "13854.59361782823\n",
      "correct:  41415\n",
      "wrong:  8585\n",
      "accuracy: 82.83 %\n",
      "error: 17.17 %\n",
      "13851.10649159623\n",
      "correct:  41425\n",
      "wrong:  8575\n",
      "accuracy: 82.85 %\n",
      "error: 17.15 %\n",
      "13847.655772793187\n",
      "correct:  41422\n",
      "wrong:  8578\n",
      "accuracy: 82.844 %\n",
      "error: 17.156 %\n",
      "13844.226571886114\n",
      "correct:  41417\n",
      "wrong:  8583\n",
      "accuracy: 82.834 %\n",
      "error: 17.166 %\n",
      "13840.878515432083\n",
      "correct:  41414\n",
      "wrong:  8586\n",
      "accuracy: 82.828 %\n",
      "error: 17.172 %\n",
      "13837.548341517078\n",
      "correct:  41430\n",
      "wrong:  8570\n",
      "accuracy: 82.86 %\n",
      "error: 17.14 %\n",
      "13834.273029037788\n",
      "correct:  41418\n",
      "wrong:  8582\n",
      "accuracy: 82.836 %\n",
      "error: 17.164 %\n",
      "13831.039197985434\n",
      "correct:  41422\n",
      "wrong:  8578\n",
      "accuracy: 82.844 %\n",
      "error: 17.156 %\n",
      "13827.842032206845\n",
      "correct:  41423\n",
      "wrong:  8577\n",
      "accuracy: 82.846 %\n",
      "error: 17.154 %\n",
      "13824.707590795017\n",
      "100 iterations took 19155.662407636642 seconds.\n",
      "\n",
      "correct:  8338\n",
      "wrong:  1662\n",
      "accuracy: 83.38 %\n",
      "error: 16.62 %\n",
      "correct:  8326\n",
      "wrong:  1674\n",
      "accuracy: 83.26 %\n",
      "error: 16.74 %\n",
      "correct:  41423\n",
      "wrong:  8577\n",
      "accuracy: 82.846 %\n",
      "error: 17.154 %\n",
      "13824.088643865633\n",
      "correct:  41423\n",
      "wrong:  8577\n",
      "accuracy: 82.846 %\n",
      "error: 17.154 %\n",
      "13823.47396973166\n",
      "correct:  41421\n",
      "wrong:  8579\n",
      "accuracy: 82.842 %\n",
      "error: 17.158 %\n",
      "13822.864724150824\n",
      "correct:  41424\n",
      "wrong:  8576\n",
      "accuracy: 82.848 %\n",
      "error: 17.152 %\n",
      "13822.260077142497\n",
      "correct:  41422\n",
      "wrong:  8578\n",
      "accuracy: 82.844 %\n",
      "error: 17.156 %\n",
      "13821.65725685583\n",
      "correct:  41418\n",
      "wrong:  8582\n",
      "accuracy: 82.836 %\n",
      "error: 17.164 %\n",
      "13821.059841972441\n",
      "correct:  41422\n",
      "wrong:  8578\n",
      "accuracy: 82.844 %\n",
      "error: 17.156 %\n",
      "13820.464239765659\n",
      "correct:  41420\n",
      "wrong:  8580\n",
      "accuracy: 82.84 %\n",
      "error: 17.16 %\n",
      "13819.872776983157\n",
      "correct:  41420\n",
      "wrong:  8580\n",
      "accuracy: 82.84 %\n",
      "error: 17.16 %\n",
      "13819.289583608223\n",
      "correct:  41419\n",
      "wrong:  8581\n",
      "accuracy: 82.838 %\n",
      "error: 17.162 %\n",
      "13818.711056817478\n",
      "correct:  41416\n",
      "wrong:  8584\n",
      "accuracy: 82.832 %\n",
      "error: 17.168 %\n",
      "13818.133179054203\n",
      "correct:  41414\n",
      "wrong:  8586\n",
      "accuracy: 82.828 %\n",
      "error: 17.172 %\n",
      "13817.566538305608\n",
      "correct:  41410\n",
      "wrong:  8590\n",
      "accuracy: 82.82 %\n",
      "error: 17.18 %\n",
      "13817.008266201992\n",
      "correct:  41412\n",
      "wrong:  8588\n",
      "accuracy: 82.824 %\n",
      "error: 17.176 %\n",
      "13816.447995235341\n",
      "correct:  41412\n",
      "wrong:  8588\n",
      "accuracy: 82.824 %\n",
      "error: 17.176 %\n",
      "13815.894557031328\n",
      "correct:  41408\n",
      "wrong:  8592\n",
      "accuracy: 82.816 %\n",
      "error: 17.184 %\n",
      "13815.354179784452\n",
      "correct:  41411\n",
      "wrong:  8589\n",
      "accuracy: 82.822 %\n",
      "error: 17.178 %\n",
      "13814.818521563613\n",
      "correct:  41411\n",
      "wrong:  8589\n",
      "accuracy: 82.822 %\n",
      "error: 17.178 %\n",
      "13814.290327630699\n",
      "correct:  41409\n",
      "wrong:  8591\n",
      "accuracy: 82.818 %\n",
      "error: 17.182 %\n",
      "13813.766431598404\n",
      "correct:  41407\n",
      "wrong:  8593\n",
      "accuracy: 82.814 %\n",
      "error: 17.186 %\n",
      "13813.247425102154\n",
      "correct:  41406\n",
      "wrong:  8594\n",
      "accuracy: 82.812 %\n",
      "error: 17.188 %\n",
      "13812.73529678247\n",
      "correct:  41407\n",
      "wrong:  8593\n",
      "accuracy: 82.814 %\n",
      "error: 17.186 %\n",
      "13812.230788054007\n",
      "correct:  41401\n",
      "wrong:  8599\n",
      "accuracy: 82.802 %\n",
      "error: 17.198 %\n",
      "13811.730765619444\n",
      "correct:  41400\n",
      "wrong:  8600\n",
      "accuracy: 82.8 %\n",
      "error: 17.2 %\n",
      "13811.233401319214\n",
      "correct:  41401\n",
      "wrong:  8599\n",
      "accuracy: 82.802 %\n",
      "error: 17.198 %\n",
      "13810.741384455061\n",
      "correct:  41400\n",
      "wrong:  8600\n",
      "accuracy: 82.8 %\n",
      "error: 17.2 %\n",
      "13810.256123176196\n",
      "correct:  41397\n",
      "wrong:  8603\n",
      "accuracy: 82.794 %\n",
      "error: 17.206 %\n",
      "13809.7734741081\n",
      "correct:  41396\n",
      "wrong:  8604\n",
      "accuracy: 82.792 %\n",
      "error: 17.208 %\n",
      "13809.294281530812\n",
      "correct:  41395\n",
      "wrong:  8605\n",
      "accuracy: 82.79 %\n",
      "error: 17.21 %\n",
      "13808.82354755048\n",
      "correct:  41394\n",
      "wrong:  8606\n",
      "accuracy: 82.788 %\n",
      "error: 17.212 %\n",
      "13808.354376297584\n",
      "correct:  41390\n",
      "wrong:  8610\n",
      "accuracy: 82.78 %\n",
      "error: 17.22 %\n",
      "13807.88713114192\n",
      "correct:  41384\n",
      "wrong:  8616\n",
      "accuracy: 82.768 %\n",
      "error: 17.232 %\n",
      "13807.422538326417\n",
      "correct:  41384\n",
      "wrong:  8616\n",
      "accuracy: 82.768 %\n",
      "error: 17.232 %\n",
      "13806.959157176421\n",
      "correct:  41380\n",
      "wrong:  8620\n",
      "accuracy: 82.76 %\n",
      "error: 17.24 %\n",
      "13806.499557157074\n",
      "correct:  41380\n",
      "wrong:  8620\n",
      "accuracy: 82.76 %\n",
      "error: 17.24 %\n",
      "13806.042011428652\n",
      "correct:  41378\n",
      "wrong:  8622\n",
      "accuracy: 82.756 %\n",
      "error: 17.244 %\n",
      "13805.589939109528\n",
      "correct:  41377\n",
      "wrong:  8623\n",
      "accuracy: 82.754 %\n",
      "error: 17.246 %\n",
      "13805.135751200805\n",
      "correct:  41378\n",
      "wrong:  8622\n",
      "accuracy: 82.756 %\n",
      "error: 17.244 %\n",
      "13804.679620331222\n",
      "correct:  41380\n",
      "wrong:  8620\n",
      "accuracy: 82.76 %\n",
      "error: 17.24 %\n",
      "13804.22308977498\n",
      "correct:  41384\n",
      "wrong:  8616\n",
      "accuracy: 82.768 %\n",
      "error: 17.232 %\n",
      "13803.770659611779\n",
      "correct:  41382\n",
      "wrong:  8618\n",
      "accuracy: 82.764 %\n",
      "error: 17.236 %\n",
      "13803.317496871581\n",
      "correct:  41386\n",
      "wrong:  8614\n",
      "accuracy: 82.772 %\n",
      "error: 17.228 %\n",
      "13802.865213801495\n",
      "correct:  41389\n",
      "wrong:  8611\n",
      "accuracy: 82.778 %\n",
      "error: 17.222 %\n",
      "13802.405821933859\n",
      "correct:  41382\n",
      "wrong:  8618\n",
      "accuracy: 82.764 %\n",
      "error: 17.236 %\n",
      "13801.95000384991\n",
      "correct:  41385\n",
      "wrong:  8615\n",
      "accuracy: 82.77 %\n",
      "error: 17.23 %\n",
      "13801.493191578546\n",
      "correct:  41383\n",
      "wrong:  8617\n",
      "accuracy: 82.766 %\n",
      "error: 17.234 %\n",
      "13801.033839279067\n",
      "correct:  41376\n",
      "wrong:  8624\n",
      "accuracy: 82.752 %\n",
      "error: 17.248 %\n",
      "13800.573326025888\n",
      "correct:  41333\n",
      "wrong:  8667\n",
      "accuracy: 82.666 %\n",
      "error: 17.334 %\n",
      "13800.10655450384\n",
      "correct:  41332\n",
      "wrong:  8668\n",
      "accuracy: 82.664 %\n",
      "error: 17.336 %\n",
      "13799.640028764246\n",
      "correct:  41328\n",
      "wrong:  8672\n",
      "accuracy: 82.656 %\n",
      "error: 17.344 %\n",
      "13799.1682556173\n",
      "correct:  41330\n",
      "wrong:  8670\n",
      "accuracy: 82.66 %\n",
      "error: 17.34 %\n",
      "13798.691262847573\n",
      "correct:  41330\n",
      "wrong:  8670\n",
      "accuracy: 82.66 %\n",
      "error: 17.34 %\n",
      "13798.215969106675\n",
      "correct:  41330\n",
      "wrong:  8670\n",
      "accuracy: 82.66 %\n",
      "error: 17.34 %\n",
      "13797.736299725824\n",
      "correct:  41328\n",
      "wrong:  8672\n",
      "accuracy: 82.656 %\n",
      "error: 17.344 %\n",
      "13797.257842225697\n",
      "correct:  41327\n",
      "wrong:  8673\n",
      "accuracy: 82.654 %\n",
      "error: 17.346 %\n",
      "13796.778188787135\n",
      "correct:  41320\n",
      "wrong:  8680\n",
      "accuracy: 82.64 %\n",
      "error: 17.36 %\n",
      "13796.293455842675\n",
      "correct:  41315\n",
      "wrong:  8685\n",
      "accuracy: 82.63 %\n",
      "error: 17.37 %\n",
      "13795.801828793483\n",
      "correct:  41315\n",
      "wrong:  8685\n",
      "accuracy: 82.63 %\n",
      "error: 17.37 %\n",
      "13795.314432525945\n",
      "correct:  41311\n",
      "wrong:  8689\n",
      "accuracy: 82.622 %\n",
      "error: 17.378 %\n",
      "13794.821318223472\n",
      "correct:  41309\n",
      "wrong:  8691\n",
      "accuracy: 82.618 %\n",
      "error: 17.382 %\n",
      "13794.32626987176\n",
      "correct:  41318\n",
      "wrong:  8682\n",
      "accuracy: 82.636 %\n",
      "error: 17.364 %\n",
      "13793.82678774806\n",
      "correct:  41318\n",
      "wrong:  8682\n",
      "accuracy: 82.636 %\n",
      "error: 17.364 %\n",
      "13793.327164972952\n",
      "correct:  41313\n",
      "wrong:  8687\n",
      "accuracy: 82.626 %\n",
      "error: 17.374 %\n",
      "13792.823035673982\n",
      "correct:  41310\n",
      "wrong:  8690\n",
      "accuracy: 82.62 %\n",
      "error: 17.38 %\n",
      "13792.31354071355\n",
      "correct:  41310\n",
      "wrong:  8690\n",
      "accuracy: 82.62 %\n",
      "error: 17.38 %\n",
      "13791.799707233826\n",
      "correct:  41307\n",
      "wrong:  8693\n",
      "accuracy: 82.614 %\n",
      "error: 17.386 %\n",
      "13791.281301083598\n",
      "correct:  41301\n",
      "wrong:  8699\n",
      "accuracy: 82.602 %\n",
      "error: 17.398 %\n",
      "13790.757803218139\n",
      "correct:  41297\n",
      "wrong:  8703\n",
      "accuracy: 82.594 %\n",
      "error: 17.406 %\n",
      "13790.233047035812\n",
      "correct:  41302\n",
      "wrong:  8698\n",
      "accuracy: 82.604 %\n",
      "error: 17.396 %\n",
      "13789.702826602579\n",
      "correct:  41301\n",
      "wrong:  8699\n",
      "accuracy: 82.602 %\n",
      "error: 17.398 %\n",
      "13789.169790288337\n",
      "correct:  41295\n",
      "wrong:  8705\n",
      "accuracy: 82.59 %\n",
      "error: 17.41 %\n",
      "13788.632406636798\n",
      "correct:  41295\n",
      "wrong:  8705\n",
      "accuracy: 82.59 %\n",
      "error: 17.41 %\n",
      "13788.08818263493\n",
      "correct:  41300\n",
      "wrong:  8700\n",
      "accuracy: 82.6 %\n",
      "error: 17.4 %\n",
      "13787.536880477785\n",
      "correct:  41299\n",
      "wrong:  8701\n",
      "accuracy: 82.598 %\n",
      "error: 17.402 %\n",
      "13786.985306376322\n",
      "correct:  41299\n",
      "wrong:  8701\n",
      "accuracy: 82.598 %\n",
      "error: 17.402 %\n",
      "13786.420456942942\n",
      "correct:  41298\n",
      "wrong:  8702\n",
      "accuracy: 82.596 %\n",
      "error: 17.404 %\n",
      "13785.851841986576\n",
      "correct:  41293\n",
      "wrong:  8707\n",
      "accuracy: 82.586 %\n",
      "error: 17.414 %\n",
      "13785.284708796327\n",
      "correct:  41294\n",
      "wrong:  8706\n",
      "accuracy: 82.588 %\n",
      "error: 17.412 %\n",
      "13784.705009288411\n",
      "correct:  41295\n",
      "wrong:  8705\n",
      "accuracy: 82.59 %\n",
      "error: 17.41 %\n",
      "13784.12287230504\n",
      "correct:  41293\n",
      "wrong:  8707\n",
      "accuracy: 82.586 %\n",
      "error: 17.414 %\n",
      "13783.543449810286\n",
      "correct:  41290\n",
      "wrong:  8710\n",
      "accuracy: 82.58 %\n",
      "error: 17.42 %\n",
      "13782.952529097027\n",
      "correct:  41291\n",
      "wrong:  8709\n",
      "accuracy: 82.582 %\n",
      "error: 17.418 %\n",
      "13782.361300622493\n",
      "correct:  41290\n",
      "wrong:  8710\n",
      "accuracy: 82.58 %\n",
      "error: 17.42 %\n",
      "13781.767938337807\n",
      "correct:  41291\n",
      "wrong:  8709\n",
      "accuracy: 82.582 %\n",
      "error: 17.418 %\n",
      "13781.171058126298\n",
      "correct:  41289\n",
      "wrong:  8711\n",
      "accuracy: 82.578 %\n",
      "error: 17.422 %\n",
      "13780.566791106668\n",
      "correct:  41286\n",
      "wrong:  8714\n",
      "accuracy: 82.572 %\n",
      "error: 17.428 %\n",
      "13779.960048157525\n",
      "correct:  41287\n",
      "wrong:  8713\n",
      "accuracy: 82.574 %\n",
      "error: 17.426 %\n",
      "13779.350295835338\n",
      "correct:  41286\n",
      "wrong:  8714\n",
      "accuracy: 82.572 %\n",
      "error: 17.428 %\n",
      "13778.742570606018\n",
      "correct:  41285\n",
      "wrong:  8715\n",
      "accuracy: 82.57 %\n",
      "error: 17.43 %\n",
      "13778.134095012265\n",
      "correct:  41287\n",
      "wrong:  8713\n",
      "accuracy: 82.574 %\n",
      "error: 17.426 %\n",
      "13777.52209300346\n",
      "correct:  41285\n",
      "wrong:  8715\n",
      "accuracy: 82.57 %\n",
      "error: 17.43 %\n",
      "13776.909349843949\n",
      "correct:  41289\n",
      "wrong:  8711\n",
      "accuracy: 82.578 %\n",
      "error: 17.422 %\n",
      "13776.301553955867\n",
      "correct:  41290\n",
      "wrong:  8710\n",
      "accuracy: 82.58 %\n",
      "error: 17.42 %\n",
      "13775.68919278674\n",
      "correct:  41289\n",
      "wrong:  8711\n",
      "accuracy: 82.578 %\n",
      "error: 17.422 %\n",
      "13775.074594463364\n",
      "correct:  41284\n",
      "wrong:  8716\n",
      "accuracy: 82.568 %\n",
      "error: 17.432 %\n",
      "13774.459314431091\n",
      "correct:  41281\n",
      "wrong:  8719\n",
      "accuracy: 82.562 %\n",
      "error: 17.438 %\n",
      "13773.843409321149\n",
      "correct:  41284\n",
      "wrong:  8716\n",
      "accuracy: 82.568 %\n",
      "error: 17.432 %\n",
      "13773.226926778143\n",
      "correct:  41287\n",
      "wrong:  8713\n",
      "accuracy: 82.574 %\n",
      "error: 17.426 %\n",
      "13772.611257037013\n",
      "correct:  41284\n",
      "wrong:  8716\n",
      "accuracy: 82.568 %\n",
      "error: 17.432 %\n",
      "13771.99073691888\n",
      "correct:  41283\n",
      "wrong:  8717\n",
      "accuracy: 82.566 %\n",
      "error: 17.434 %\n",
      "13771.373449025943\n",
      "correct:  41279\n",
      "wrong:  8721\n",
      "accuracy: 82.558 %\n",
      "error: 17.442 %\n",
      "13770.758881809823\n",
      "correct:  41277\n",
      "wrong:  8723\n",
      "accuracy: 82.554 %\n",
      "error: 17.446 %\n",
      "13770.14176980345\n",
      "correct:  41279\n",
      "wrong:  8721\n",
      "accuracy: 82.558 %\n",
      "error: 17.442 %\n",
      "13769.514395001841\n",
      "correct:  41278\n",
      "wrong:  8722\n",
      "accuracy: 82.556 %\n",
      "error: 17.444 %\n",
      "13768.891272499392\n",
      "correct:  41278\n",
      "wrong:  8722\n",
      "accuracy: 82.556 %\n",
      "error: 17.444 %\n",
      "13768.265848835483\n",
      "correct:  41279\n",
      "wrong:  8721\n",
      "accuracy: 82.558 %\n",
      "error: 17.442 %\n",
      "13767.634136657805\n",
      "correct:  41275\n",
      "wrong:  8725\n",
      "accuracy: 82.55 %\n",
      "error: 17.45 %\n",
      "13767.001805498368\n",
      "correct:  41280\n",
      "wrong:  8720\n",
      "accuracy: 82.56 %\n",
      "error: 17.44 %\n",
      "13766.370212079542\n",
      "correct:  41284\n",
      "wrong:  8716\n",
      "accuracy: 82.568 %\n",
      "error: 17.432 %\n",
      "13765.736982100214\n",
      "correct:  41286\n",
      "wrong:  8714\n",
      "accuracy: 82.572 %\n",
      "error: 17.428 %\n",
      "13765.098468019796\n",
      "correct:  41283\n",
      "wrong:  8717\n",
      "accuracy: 82.566 %\n",
      "error: 17.434 %\n",
      "13764.460661432317\n",
      "correct:  41287\n",
      "wrong:  8713\n",
      "accuracy: 82.574 %\n",
      "error: 17.426 %\n",
      "13763.824670597385\n",
      "correct:  41288\n",
      "wrong:  8712\n",
      "accuracy: 82.576 %\n",
      "error: 17.424 %\n",
      "13763.176013003513\n",
      "correct:  41284\n",
      "wrong:  8716\n",
      "accuracy: 82.568 %\n",
      "error: 17.432 %\n",
      "13762.52826547063\n",
      "correct:  41284\n",
      "wrong:  8716\n",
      "accuracy: 82.568 %\n",
      "error: 17.432 %\n",
      "13761.876481331903\n",
      "correct:  41282\n",
      "wrong:  8718\n",
      "accuracy: 82.564 %\n",
      "error: 17.436 %\n",
      "13761.22529502483\n",
      "correct:  41283\n",
      "wrong:  8717\n",
      "accuracy: 82.566 %\n",
      "error: 17.434 %\n",
      "13760.567525900966\n",
      "correct:  41282\n",
      "wrong:  8718\n",
      "accuracy: 82.564 %\n",
      "error: 17.436 %\n",
      "13759.91585985827\n",
      "correct:  41281\n",
      "wrong:  8719\n",
      "accuracy: 82.562 %\n",
      "error: 17.438 %\n",
      "13759.25686490445\n",
      "correct:  41283\n",
      "wrong:  8717\n",
      "accuracy: 82.566 %\n",
      "error: 17.434 %\n",
      "13758.59347014648\n",
      "correct:  41282\n",
      "wrong:  8718\n",
      "accuracy: 82.564 %\n",
      "error: 17.436 %\n",
      "13757.929597253637\n",
      "correct:  41283\n",
      "wrong:  8717\n",
      "accuracy: 82.566 %\n",
      "error: 17.434 %\n",
      "13757.260730047901\n",
      "correct:  41285\n",
      "wrong:  8715\n",
      "accuracy: 82.57 %\n",
      "error: 17.43 %\n",
      "13756.588740826102\n",
      "correct:  41288\n",
      "wrong:  8712\n",
      "accuracy: 82.576 %\n",
      "error: 17.424 %\n",
      "13755.916931120295\n",
      "correct:  41284\n",
      "wrong:  8716\n",
      "accuracy: 82.568 %\n",
      "error: 17.432 %\n",
      "13755.243171522417\n",
      "correct:  41280\n",
      "wrong:  8720\n",
      "accuracy: 82.56 %\n",
      "error: 17.44 %\n",
      "13754.569753544178\n",
      "correct:  41278\n",
      "wrong:  8722\n",
      "accuracy: 82.556 %\n",
      "error: 17.444 %\n",
      "13753.89702596686\n",
      "correct:  41276\n",
      "wrong:  8724\n",
      "accuracy: 82.552 %\n",
      "error: 17.448 %\n",
      "13753.222877566393\n",
      "correct:  41278\n",
      "wrong:  8722\n",
      "accuracy: 82.556 %\n",
      "error: 17.444 %\n",
      "13752.544213236164\n",
      "correct:  41276\n",
      "wrong:  8724\n",
      "accuracy: 82.552 %\n",
      "error: 17.448 %\n",
      "13751.865706143955\n",
      "correct:  41273\n",
      "wrong:  8727\n",
      "accuracy: 82.546 %\n",
      "error: 17.454 %\n",
      "13751.186195296335\n",
      "correct:  41272\n",
      "wrong:  8728\n",
      "accuracy: 82.544 %\n",
      "error: 17.456 %\n",
      "13750.509439123602\n",
      "correct:  41269\n",
      "wrong:  8731\n",
      "accuracy: 82.538 %\n",
      "error: 17.462 %\n",
      "13749.832143510346\n",
      "correct:  41271\n",
      "wrong:  8729\n",
      "accuracy: 82.542 %\n",
      "error: 17.458 %\n",
      "13749.155640621471\n",
      "correct:  41267\n",
      "wrong:  8733\n",
      "accuracy: 82.534 %\n",
      "error: 17.466 %\n",
      "13748.47765073259\n",
      "correct:  41267\n",
      "wrong:  8733\n",
      "accuracy: 82.534 %\n",
      "error: 17.466 %\n",
      "13747.8043611979\n",
      "correct:  41266\n",
      "wrong:  8734\n",
      "accuracy: 82.532 %\n",
      "error: 17.468 %\n",
      "13747.128040126265\n",
      "correct:  41266\n",
      "wrong:  8734\n",
      "accuracy: 82.532 %\n",
      "error: 17.468 %\n",
      "13746.457712494283\n",
      "correct:  41268\n",
      "wrong:  8732\n",
      "accuracy: 82.536 %\n",
      "error: 17.464 %\n",
      "13745.790227962556\n",
      "correct:  41270\n",
      "wrong:  8730\n",
      "accuracy: 82.54 %\n",
      "error: 17.46 %\n",
      "13745.124318944523\n",
      "correct:  41265\n",
      "wrong:  8735\n",
      "accuracy: 82.53 %\n",
      "error: 17.47 %\n",
      "13744.468832990739\n",
      "correct:  41266\n",
      "wrong:  8734\n",
      "accuracy: 82.532 %\n",
      "error: 17.468 %\n",
      "13743.815952673463\n",
      "correct:  41267\n",
      "wrong:  8733\n",
      "accuracy: 82.534 %\n",
      "error: 17.466 %\n",
      "13743.17056272483\n",
      "correct:  41263\n",
      "wrong:  8737\n",
      "accuracy: 82.526 %\n",
      "error: 17.474 %\n",
      "13742.528960961625\n",
      "correct:  41266\n",
      "wrong:  8734\n",
      "accuracy: 82.532 %\n",
      "error: 17.468 %\n",
      "13741.891627346326\n",
      "correct:  41263\n",
      "wrong:  8737\n",
      "accuracy: 82.526 %\n",
      "error: 17.474 %\n",
      "13741.263677328006\n",
      "correct:  41259\n",
      "wrong:  8741\n",
      "accuracy: 82.518 %\n",
      "error: 17.482 %\n",
      "13740.639004708644\n",
      "correct:  41258\n",
      "wrong:  8742\n",
      "accuracy: 82.516 %\n",
      "error: 17.484 %\n",
      "13740.022471598011\n",
      "correct:  41265\n",
      "wrong:  8735\n",
      "accuracy: 82.53 %\n",
      "error: 17.47 %\n",
      "13739.411384641558\n",
      "correct:  41265\n",
      "wrong:  8735\n",
      "accuracy: 82.53 %\n",
      "error: 17.47 %\n",
      "13738.806915556968\n",
      "correct:  41262\n",
      "wrong:  8738\n",
      "accuracy: 82.524 %\n",
      "error: 17.476 %\n",
      "13738.215929034379\n",
      "correct:  41264\n",
      "wrong:  8736\n",
      "accuracy: 82.528 %\n",
      "error: 17.472 %\n",
      "13737.627791872845\n",
      "correct:  41261\n",
      "wrong:  8739\n",
      "accuracy: 82.522 %\n",
      "error: 17.478 %\n",
      "13737.049311787985\n",
      "correct:  41261\n",
      "wrong:  8739\n",
      "accuracy: 82.522 %\n",
      "error: 17.478 %\n",
      "13736.476640235871\n",
      "correct:  41256\n",
      "wrong:  8744\n",
      "accuracy: 82.512 %\n",
      "error: 17.488 %\n",
      "13735.91261634975\n",
      "correct:  41257\n",
      "wrong:  8743\n",
      "accuracy: 82.514 %\n",
      "error: 17.486 %\n",
      "13735.35446674722\n",
      "correct:  41257\n",
      "wrong:  8743\n",
      "accuracy: 82.514 %\n",
      "error: 17.486 %\n",
      "13734.80683178638\n",
      "correct:  41258\n",
      "wrong:  8742\n",
      "accuracy: 82.516 %\n",
      "error: 17.484 %\n",
      "13734.264308886672\n",
      "correct:  41255\n",
      "wrong:  8745\n",
      "accuracy: 82.51 %\n",
      "error: 17.49 %\n",
      "13733.734301952596\n",
      "correct:  41254\n",
      "wrong:  8746\n",
      "accuracy: 82.508 %\n",
      "error: 17.492 %\n",
      "13733.20841795616\n",
      "correct:  41255\n",
      "wrong:  8745\n",
      "accuracy: 82.51 %\n",
      "error: 17.49 %\n",
      "13732.687227713503\n",
      "correct:  41253\n",
      "wrong:  8747\n",
      "accuracy: 82.506 %\n",
      "error: 17.494 %\n",
      "13732.17663298704\n",
      "correct:  41253\n",
      "wrong:  8747\n",
      "accuracy: 82.506 %\n",
      "error: 17.494 %\n",
      "13731.668386698839\n",
      "correct:  41254\n",
      "wrong:  8746\n",
      "accuracy: 82.508 %\n",
      "error: 17.492 %\n",
      "13731.168968722408\n",
      "correct:  41256\n",
      "wrong:  8744\n",
      "accuracy: 82.512 %\n",
      "error: 17.488 %\n",
      "13730.67529101359\n",
      "correct:  41254\n",
      "wrong:  8746\n",
      "accuracy: 82.508 %\n",
      "error: 17.492 %\n",
      "13730.186666309042\n",
      "correct:  41252\n",
      "wrong:  8748\n",
      "accuracy: 82.504 %\n",
      "error: 17.496 %\n",
      "13729.706746942426\n",
      "correct:  41247\n",
      "wrong:  8753\n",
      "accuracy: 82.494 %\n",
      "error: 17.506 %\n",
      "13729.23124429859\n",
      "correct:  41244\n",
      "wrong:  8756\n",
      "accuracy: 82.488 %\n",
      "error: 17.512 %\n",
      "13728.761773560533\n",
      "correct:  41246\n",
      "wrong:  8754\n",
      "accuracy: 82.492 %\n",
      "error: 17.508 %\n",
      "13728.295450637152\n",
      "correct:  41250\n",
      "wrong:  8750\n",
      "accuracy: 82.5 %\n",
      "error: 17.5 %\n",
      "13727.836942001763\n",
      "correct:  41249\n",
      "wrong:  8751\n",
      "accuracy: 82.498 %\n",
      "error: 17.502 %\n",
      "13727.387657220099\n",
      "correct:  41248\n",
      "wrong:  8752\n",
      "accuracy: 82.496 %\n",
      "error: 17.504 %\n",
      "13726.943600242355\n",
      "correct:  41249\n",
      "wrong:  8751\n",
      "accuracy: 82.498 %\n",
      "error: 17.502 %\n",
      "13726.50478863322\n",
      "correct:  41250\n",
      "wrong:  8750\n",
      "accuracy: 82.5 %\n",
      "error: 17.5 %\n",
      "13726.069602565642\n",
      "correct:  41253\n",
      "wrong:  8747\n",
      "accuracy: 82.506 %\n",
      "error: 17.494 %\n",
      "13725.6413395243\n",
      "correct:  41250\n",
      "wrong:  8750\n",
      "accuracy: 82.5 %\n",
      "error: 17.5 %\n",
      "13725.223087352577\n",
      "correct:  41253\n",
      "wrong:  8747\n",
      "accuracy: 82.506 %\n",
      "error: 17.494 %\n",
      "13724.811600191744\n",
      "correct:  41249\n",
      "wrong:  8751\n",
      "accuracy: 82.498 %\n",
      "error: 17.502 %\n",
      "13724.400809354078\n",
      "correct:  41249\n",
      "wrong:  8751\n",
      "accuracy: 82.498 %\n",
      "error: 17.502 %\n",
      "13724.002360201139\n",
      "correct:  41252\n",
      "wrong:  8748\n",
      "accuracy: 82.504 %\n",
      "error: 17.496 %\n",
      "13723.611686149523\n",
      "correct:  41248\n",
      "wrong:  8752\n",
      "accuracy: 82.496 %\n",
      "error: 17.504 %\n",
      "13723.227338049035\n",
      "correct:  41244\n",
      "wrong:  8756\n",
      "accuracy: 82.488 %\n",
      "error: 17.512 %\n",
      "13722.852469956604\n",
      "correct:  41243\n",
      "wrong:  8757\n",
      "accuracy: 82.486 %\n",
      "error: 17.514 %\n",
      "13722.478138394528\n",
      "correct:  41240\n",
      "wrong:  8760\n",
      "accuracy: 82.48 %\n",
      "error: 17.52 %\n",
      "13722.109725590448\n",
      "correct:  41238\n",
      "wrong:  8762\n",
      "accuracy: 82.476 %\n",
      "error: 17.524 %\n",
      "13721.756120284093\n",
      "correct:  41237\n",
      "wrong:  8763\n",
      "accuracy: 82.474 %\n",
      "error: 17.526 %\n",
      "13721.404896683533\n",
      "correct:  41239\n",
      "wrong:  8761\n",
      "accuracy: 82.478 %\n",
      "error: 17.522 %\n",
      "13721.058299038621\n",
      "correct:  41240\n",
      "wrong:  8760\n",
      "accuracy: 82.48 %\n",
      "error: 17.52 %\n",
      "13720.721973218659\n",
      "correct:  41242\n",
      "wrong:  8758\n",
      "accuracy: 82.484 %\n",
      "error: 17.516 %\n",
      "13720.386644139075\n",
      "correct:  41241\n",
      "wrong:  8759\n",
      "accuracy: 82.482 %\n",
      "error: 17.518 %\n",
      "13720.059186570088\n",
      "correct:  41242\n",
      "wrong:  8758\n",
      "accuracy: 82.484 %\n",
      "error: 17.516 %\n",
      "13719.733431977927\n",
      "correct:  41243\n",
      "wrong:  8757\n",
      "accuracy: 82.486 %\n",
      "error: 17.514 %\n",
      "13719.415808060397\n",
      "correct:  41239\n",
      "wrong:  8761\n",
      "accuracy: 82.478 %\n",
      "error: 17.522 %\n",
      "13719.104477493382\n",
      "correct:  41243\n",
      "wrong:  8757\n",
      "accuracy: 82.486 %\n",
      "error: 17.514 %\n",
      "13718.790290509656\n",
      "correct:  41235\n",
      "wrong:  8765\n",
      "accuracy: 82.47 %\n",
      "error: 17.53 %\n",
      "13718.483725057175\n",
      "correct:  41241\n",
      "wrong:  8759\n",
      "accuracy: 82.482 %\n",
      "error: 17.518 %\n",
      "13718.183371453939\n",
      "correct:  41246\n",
      "wrong:  8754\n",
      "accuracy: 82.492 %\n",
      "error: 17.508 %\n",
      "13717.887667871293\n",
      "correct:  41244\n",
      "wrong:  8756\n",
      "accuracy: 82.488 %\n",
      "error: 17.512 %\n",
      "13717.594267814262\n",
      "correct:  41245\n",
      "wrong:  8755\n",
      "accuracy: 82.49 %\n",
      "error: 17.51 %\n",
      "13717.308292454918\n",
      "200 iterations took 38288.91045355797 seconds.\n",
      "\n",
      "correct:  8334\n",
      "wrong:  1666\n",
      "accuracy: 83.34 %\n",
      "error: 16.66 %\n",
      "correct:  8260\n",
      "wrong:  1740\n",
      "accuracy: 82.6 %\n",
      "error: 17.4 %\n"
     ]
    }
   ],
   "source": [
    "b = Neural_Network(expit, sigmoidPrime, MSE, MSEPrime, shape=[28**2, 30, 30, 10])\n",
    "trainingData = {}\n",
    "train1 = b.stochasticGradientDescent(train_set, 2000, 35, 5)\n",
    "trainingData[\"train1\"] = train1\n",
    "print()\n",
    "b.validation(valid_set)\n",
    "b.validation(test_set)\n",
    "train2 = b.gradientDescent(train_set, 100, 0.5)\n",
    "trainingData[\"train2\"] = train2\n",
    "print()\n",
    "b.validation(valid_set)\n",
    "b.validation(test_set)\n",
    "train3 = b.gradientDescent(train_set, 200, 0.1)\n",
    "trainingData[\"train3\"] = train3\n",
    "print()\n",
    "b.validation(valid_set)\n",
    "b.validation(test_set)\n",
    "with open('trainingData.pickle', 'wb') as handle:\n",
    "    pickle.dump(trainingData, handle, protocol = pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('trainingData.pickle', 'rb') as handle:\n",
    "    lastTrainData = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
